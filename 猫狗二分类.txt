import torch
import random
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
from torchvision import datasets, transforms
import matplotlib.pyplot as plt

#定义参数
n_epochs = 10
batch_size = 10000
learning_rate = 0.001
momentum = 0.9
log_interval = 1
random_seed = 1
torch.manual_seed(random_seed)


data_transform = transforms.Compose([transforms.Resize(84),transforms.CenterCrop(84),
    #ToTensor()能够把图片的灰度范围从0~255 变成0~1之间                                 
    transforms.ToTensor(),
   #逐channel的对图像进行标准化（均值变为0，标准差变为1），可以加快模型的收敛                                  
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
train_dataset0 = datasets.ImageFolder("E:/sql/kaggle/0/",transform = data_transform)
train_dataset1 = datasets.ImageFolder("E:/sql/kaggle/1/",transform = data_transform)
train_loader0 = torch.utils.data.DataLoader(train_dataset0,batch_size=batch_size)
train_loader1 = torch.utils.data.DataLoader(train_dataset1,batch_size=batch_size)
examples = enumerate(train_loader0)
batch_idx0, (example_data0, example_targets0) = next(examples)
examples = enumerate(train_loader1)
batch_idx1, (example_data1, example_targets1) = next(examples)
for i in range(len(example_targets1)):
    example_targets1[i]=1
    
#合并数据集
example_data = torch.cat([example_data0,example_data1],dim=0)
example_targets = torch.cat([example_targets0,example_targets1],dim=0)

#随机打乱数据集
index = [i for i in range(len(example_data))] 
random.shuffle(index)
example_data = example_data[index]
example_targets = example_targets[index]

def get_kfold_data( k, example_data, example_targets):  
    fold_size = example_data.shape[0]   # 每份的个数:数据总条数/折数（组数）
    val_start = np.int(k * fold_size)
    example_data_valid, example_targets_valid = example_data[val_start:], example_targets[val_start:]
    example_data_train = example_data[0:val_start]
    example_targets_train = example_targets[0:val_start]
    return  example_data_train, example_targets_train,  example_data_valid,example_targets_valid

example_data_train,example_targets_train,example_data_valid,example_targets_valid = get_kfold_data(0.9, example_data, example_targets)
"""
print(example_data_train.shape)
fig = plt.figure()
for i in range(9):
    plt.subplot(3,3,i+1)
    plt.tight_layout()
    plt.imshow(example_data_train[i][0], cmap='gray', interpolation='none')
    plt.title("Ground Truth: {}".format(example_targets_train[i]))
    plt.xticks([])
    plt.yticks([])
plt.show()
"""

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        #nn.Conv2d()二维卷积
        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)
        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)
#         #nn.Dropout2d()随机将整个通道置零
#         self.conv2_drop = nn.Dropout2d()
        #nn.Linear()数据线性变换
        self.fc1 = nn.Linear(16*18*18, 1024)
        self.fc2 = nn.Linear(1024, 512)
        self.fc3 = nn.Linear(512, 2)
    def forward(self, x):
        #卷积层
        x = self.conv1(x)
    #池化层  采用步长为2的最大池化
        x = F.max_pool2d(x, 2)
        #采用relu激活函数
        x = F.relu(x)
    #卷积层
        x = self.conv2(x)
    #池化层
        x = F.max_pool2d(x , 2)
        #激活函数
        x = F.relu(x)
    #全连接层
        #view()将一个多行的Tensor,拼接成一行
        x = x.view(x.size()[0],-1)
        x = F.relu(self.fc1(x))
        #每次只训练部分参数
#         x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        x = F.relu(x)
        x = F.dropout(x, training=self.training)
        x = self.fc3(x)
        x = F.relu(x)
        #返回取对数的多分类概率输出
        x = F.log_softmax(x,dim=1)
        return x

network = Net().cuda()
optimizer = optim.SGD(network.parameters(), lr=learning_rate,momentum=momentum,weight_decay=1e-5)
cirterion = nn.CrossEntropyLoss()


def train(epoch):
    train_losses = []
    train_counter = []
    for i in range(1,np.int(len(example_targets_train)/10)):
        #将梯度设置为0
        optimizer.zero_grad()
        #将数据喂入搭建的神经网络
        output = network(example_data_train[10*(i-1):10*i].cuda())
        #计算output与target误差
        loss = cirterion(output,example_targets_train[10*(i-1):10*i].cuda())
        #反向传播
        loss.backward()
        #更新模型参数
        optimizer.step() 
        if i % log_interval == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(epoch, 10*i , len(example_targets_train),
                                                                           100. * i*10 / len(example_targets_train), loss.item()))
            train_losses.append(loss.item())
            train_counter.append((i*10) + ((epoch-1)*len(example_targets_train)))
            #torch.save保存模型参数
            torch.save(network.state_dict(), './model.pth')
            torch.save(optimizer.state_dict(), './optimizer.pth')

test_losses=[]

def test():
    network.eval()
    test_loss = 0
    correct = 0
    #不能进行梯度计算的上下文管理器减少内存消耗
    with torch.no_grad():
        output = network(example_data_valid.cuda())
        #.item()取出单元素张量的元素值并返回该值，保持原元素类型不变
        _, predicted = torch.max(output.data, 1)
        loss = cirterion(output,example_targets_valid.cuda())
        test_loss += loss.item()
        correct += (predicted == example_targets_valid.cuda().data).sum()
    test_losses.append(test_loss)
    print('\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(test_loss, correct,
                                                                              len(example_targets_valid),100. *correct / len(example_targets_valid)))
for epoch in range(1, n_epochs + 1):
    train(epoch)
    test()  
